{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "a417d3d5-e8ff-47b9-b708-df738924ccd1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import pickle\n",
    "# # 从文件中读取DataFrame对象\n",
    "# with open('jianhuatest.pkl', 'rb') as f:\n",
    "#     encoded_df = pickle.load(f)\n",
    "# 读取a.csv和b.csv文件\n",
    "df_a = pd.read_csv(r\"D:\\桌面\\大数据竞赛\\训练集竞赛2\\cwtz_train.csv\")\n",
    "df_b = pd.read_excel(r\"D:\\桌面\\大数据竞赛\\文本连接.xlsx\")\n",
    "X_text = df_b[\"Report Texts\"]\n",
    "X_numerical = df_a.iloc[:, 1:-1].values\n",
    "y = df_a.iloc[:, -1].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "ca2b3273-df38-4e55-bf88-fc7a4c201507",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import roc_auc_score\n",
    "\n",
    "import torch\n",
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "from torch import nn, optim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "38fef828-add0-4760-8d71-b6e39527c28d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_a = pd.read_csv('train.csv').sample(frac = 0.1, random_state=42)\n",
    "# X_numerical = df_a.iloc[:, 1:-2].values\n",
    "# y = df_a.iloc[:, -2].values\n",
    "# X_text = df_a.iloc[:, -1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "6f3b3196-dab5-4681-831e-fbbc132ba4d3",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# 对文本特征进行向量化处理\n",
    "vectorizer = CountVectorizer()\n",
    "X_text = vectorizer.fit_transform(X_text).toarray()\n",
    "\n",
    "# 对数字特征进行标准化处理\n",
    "scaler = StandardScaler()\n",
    "X_numerical = scaler.fit_transform(X_numerical)\n",
    "\n",
    "# 划分训练集和测试集\n",
    "X_text_train, X_text_test, X_numerical_train, X_numerical_test, y_train, y_test = train_test_split(\n",
    "    X_text, X_numerical, y, test_size=0.2, random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "57d06f74-db42-4051-ac4f-d17889eafd88",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "42668"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(X_text[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "a6c2d3ad-d64d-42ba-9545-8ff96b173288",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7236"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(X_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d54face0-4230-4816-a883-dc0948e99e6a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2fa1e7c7-c317-4b41-983f-db91d09c7718",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "b106dcc1-baab-4d1d-b3c2-3a3994b5b066",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 将数据转换为PyTorch张量\n",
    "X_text_train = torch.tensor(X_text_train)\n",
    "X_text_test = torch.tensor(X_text_test)\n",
    "X_numerical_train = torch.tensor(X_numerical_train, dtype=torch.float32)\n",
    "X_numerical_test = torch.tensor(X_numerical_test, dtype=torch.float32)\n",
    "y_train = torch.tensor(y_train, dtype=torch.float32)\n",
    "y_test = torch.tensor(y_test, dtype=torch.float32)\n",
    "\n",
    "# 将数据封装成TensorDataset\n",
    "train_dataset = TensorDataset(X_text_train, X_numerical_train, y_train)\n",
    "test_dataset = TensorDataset(X_text_test, X_numerical_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "539992f9-4e0f-4dbf-8f8e-7fbbc5940620",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 定义批量大小和数据加载器\n",
    "batch_size = 16\n",
    "train_dataloader = DataLoader(train_dataset, batch_size=batch_size)\n",
    "test_dataloader = DataLoader(test_dataset, batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "c49ce87f-f127-44e4-b875-d188f6d5e130",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 定义模型\n",
    "class MyModel(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.text_embedding = nn.Embedding(num_embeddings=116, embedding_dim=100)\n",
    "        self.text_rnn = nn.LSTM(input_size=100, hidden_size=64, batch_first=True)\n",
    "        self.linear1 = nn.Linear(in_features=116, out_features=32)\n",
    "        self.linear2 = nn.Linear(in_features=32, out_features=1)\n",
    "        self.relu = nn.ReLU()\n",
    "        self.sigmoid = nn.Sigmoid()\n",
    "\n",
    "    def forward(self, text, numerical):\n",
    "        text = self.text_embedding(text)\n",
    "        text_output, _ = self.text_rnn(text)\n",
    "        text_output = text_output[:, -1, :]\n",
    "        x = torch.cat([text_output, numerical], dim=1)\n",
    "        x = self.relu(self.linear1(x))\n",
    "        x = self.sigmoid(self.linear2(x))\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "167ce695-c0eb-42c5-9cb8-e737cb6fe0a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 将模型移动到GPU上\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model = MyModel().to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "f2a2e0f4-4600-47e2-b97c-b5a3571ca5ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 定义损失函数和优化器\n",
    "criterion = nn.BCELoss()\n",
    "optimizer = optim.Adam(model.parameters())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3f32267-22a0-420f-8e87-37c8f723dbe7",
   "metadata": {},
   "outputs": [],
   "source": [
    "#注意，这里由于模型错误，运行下列代码需要数小时的代码，而且效果不好，错误原因读者可自行理解"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "c0033a15-4e2f-40f2-a2bb-cd99ffc20a71",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Input \u001b[1;32mIn [24]\u001b[0m, in \u001b[0;36m<cell line: 6>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     16\u001b[0m output \u001b[38;5;241m=\u001b[39m model(text, numerical)\n\u001b[0;32m     17\u001b[0m loss \u001b[38;5;241m=\u001b[39m criterion(output\u001b[38;5;241m.\u001b[39msqueeze(), label)\n\u001b[1;32m---> 18\u001b[0m \u001b[43mloss\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     19\u001b[0m optimizer\u001b[38;5;241m.\u001b[39mstep()\n\u001b[0;32m     20\u001b[0m train_loss \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m loss\u001b[38;5;241m.\u001b[39mitem() \u001b[38;5;241m*\u001b[39m \u001b[38;5;28mlen\u001b[39m(batch)\n",
      "File \u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\torch\\_tensor.py:487\u001b[0m, in \u001b[0;36mTensor.backward\u001b[1;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[0;32m    477\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m has_torch_function_unary(\u001b[38;5;28mself\u001b[39m):\n\u001b[0;32m    478\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m handle_torch_function(\n\u001b[0;32m    479\u001b[0m         Tensor\u001b[38;5;241m.\u001b[39mbackward,\n\u001b[0;32m    480\u001b[0m         (\u001b[38;5;28mself\u001b[39m,),\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    485\u001b[0m         inputs\u001b[38;5;241m=\u001b[39minputs,\n\u001b[0;32m    486\u001b[0m     )\n\u001b[1;32m--> 487\u001b[0m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mautograd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    488\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgradient\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minputs\u001b[49m\n\u001b[0;32m    489\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\torch\\autograd\\__init__.py:200\u001b[0m, in \u001b[0;36mbackward\u001b[1;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[0;32m    195\u001b[0m     retain_graph \u001b[38;5;241m=\u001b[39m create_graph\n\u001b[0;32m    197\u001b[0m \u001b[38;5;66;03m# The reason we repeat same the comment below is that\u001b[39;00m\n\u001b[0;32m    198\u001b[0m \u001b[38;5;66;03m# some Python versions print out the first line of a multi-line function\u001b[39;00m\n\u001b[0;32m    199\u001b[0m \u001b[38;5;66;03m# calls in the traceback and some print out the last line\u001b[39;00m\n\u001b[1;32m--> 200\u001b[0m \u001b[43mVariable\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_execution_engine\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun_backward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# Calls into the C++ engine to run the backward pass\u001b[39;49;00m\n\u001b[0;32m    201\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtensors\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgrad_tensors_\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    202\u001b[0m \u001b[43m    \u001b[49m\u001b[43mallow_unreachable\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maccumulate_grad\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# 训练模型\n",
    "num_epochs = 4\n",
    "train_losses = []\n",
    "test_losses = []\n",
    "test_auc_scores = []\n",
    "for epoch in range(num_epochs):\n",
    "    # 训练模型\n",
    "    train_loss = 0.0\n",
    "    model.train()\n",
    "    for i, batch in enumerate(train_dataloader):\n",
    "        text, numerical, label = batch\n",
    "        text = text.to(device)\n",
    "        numerical = numerical.to(device)\n",
    "        label = label.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        output = model(text, numerical)\n",
    "        loss = criterion(output.squeeze(), label)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        train_loss += loss.item() * len(batch)\n",
    "    train_loss /= len(train_dataset)\n",
    "    train_losses.append(train_loss)\n",
    "\n",
    "    # 测试模型\n",
    "    test_loss = 0.0\n",
    "    predictions = []\n",
    "    targets = []\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        for batch in test_dataloader:\n",
    "            text, numerical, label = batch\n",
    "            text = text.to(device)\n",
    "            numerical = numerical.to(device)\n",
    "            label = label.to(device)\n",
    "            output = model(text, numerical)\n",
    "            loss = criterion(output.squeeze(), label)\n",
    "            test_loss += loss.item() * len(batch)\n",
    "            predictions.append(output.cpu().numpy())\n",
    "            targets.append(label.cpu().numpy())\n",
    "    test_loss /= len(test_dataset)\n",
    "    test_losses.append(test_loss)\n",
    "    predictions = np.concatenate(predictions)\n",
    "    targets = np.concatenate(targets)\n",
    "    test_auc_score = roc_auc_score(targets, predictions)\n",
    "    test_auc_scores.append(test_auc_score)\n",
    "\n",
    "    print(f\"Epoch {epoch + 1:02d}, \"\n",
    "          f\"Train Loss: {train_loss:.4f}, \"\n",
    "          f\"Test Loss: {test_loss:.4f}, \"\n",
    "          f\"Test AUC: {test_auc_score:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e6d8ef6-dd08-4742-87df-86e952c4ebbf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 绘制 loss 和 AUC 曲线\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "fig, ax = plt.subplots(1, 2, figsize=(12, 4))\n",
    "ax[0].plot(train_losses, label=\"Train Loss\")\n",
    "ax[0].plot(test_losses, label=\"Test Loss\")\n",
    "ax[0].set_xlabel(\"Epoch\")\n",
    "ax[0].set_ylabel(\"Loss\")\n",
    "ax[0].legend()\n",
    "ax[1].plot(test_auc_scores)\n",
    "ax[1].set_xlabel(\"Epoch\")\n",
    "ax[1].set_ylabel(\"AUC\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b79acf8-6932-4304-87c3-a799edcf0af9",
   "metadata": {},
   "outputs": [],
   "source": [
    "sum(predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc8b1b61-b2d9-4cd6-b6ea-178dd074a180",
   "metadata": {},
   "outputs": [],
   "source": [
    "sum(targets)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0f43455-6ff9-4ee1-a7c9-a2ffd29f58fc",
   "metadata": {},
   "source": [
    "##  测试集给出结果"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f77ed018-a6d2-4355-b597-64e7e9cf05ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_a = pd.read_csv(r\"D:\\桌面\\cwtz_test.csv\")\n",
    "df_b = pd.read_excel(r\"D:\\桌面\\连接文本test.xlsx\")\n",
    "\n",
    "# 将文本特征和数字特征分离\n",
    "X_text_test = df_b.iloc[:, 1].values\n",
    "X_numerical_test = df_a.iloc[:, :-1].values\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e641fc7-f970-4393-918d-7441bd351175",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 对文本特征进行向量化处理\n",
    "vectorizer = CountVectorizer()\n",
    "X_text_test = vectorizer.fit_transform(X_text_test).toarray()\n",
    "\n",
    "# 对数字特征进行标准化处理\n",
    "scaler = StandardScaler()\n",
    "X_numerical_test = scaler.fit_transform(X_numerical_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f73aae2-0174-4fd0-b9d9-21ac79c91aa0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # 将预处理后的数据转换为PyTorch张量\n",
    "X_text_test = torch.tensor(X_text_test)\n",
    "X_numerical_test = torch.tensor(X_numerical_test, dtype=torch.float32)\n",
    "\n",
    "# # 将数据封装成TensorDataset\n",
    "test_dataset = TensorDataset(X_text_test, X_numerical_test)\n",
    "\n",
    "# 定义批量大小和数据加载器\n",
    "batch_size = 32\n",
    "test_dataloader = DataLoader(test_dataset, batch_size=batch_size)\n",
    "\n",
    "# 使用训练好的模型进行预测\n",
    "predictions = []\n",
    "model.eval()  # 切换为评估模式\n",
    "with torch.no_grad():  # 禁用梯度计算，加速推理过程\n",
    "    for batch in test_dataloader:\n",
    "        text, numerical = batch\n",
    "        text = text.to(device)\n",
    "        numerical = numerical.to(device)\n",
    "        output = model(text, numerical)\n",
    "        predictions.extend(output.cpu().numpy().tolist())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7214eee9-0f66-474f-b555-894012552d3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 输出预测结果\n",
    "jieguo=[]\n",
    "jieguo=[x[0] for x in predictions ]\n",
    "df_test=pd.read_excel(r\"D:\\桌面\\竞赛二结果.xlsx\")\n",
    "df_test['预测结果'] = jieguo\n",
    "df_test.to_excel(r\"D:\\桌面\\竞赛二结果.xlsx\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b45ee719-754c-4b77-82a1-7813641a874b",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7735984-56f3-4df8-a1f7-98f0a218cbe9",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(jieguo)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6279f675-433d-47ac-aea3-5b708c3231b5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "767e561f-69f7-45f9-bb15-08baaeb75087",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "3da82fac-d77d-4197-9fdf-cde32229cc8b",
   "metadata": {},
   "source": [
    "## 模块展开详解"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f5d3b5e-f257-42ee-8365-b326ee0010f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MyModel(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.text_embedding = nn.Embedding(num_embeddings=116, embedding_dim=100)\n",
    "        self.text_rnn = nn.LSTM(input_size=100, hidden_size=64, batch_first=True)\n",
    "        self.linear1 = nn.Linear(in_features=116, out_features=32)\n",
    "        self.linear2 = nn.Linear(in_features=32, out_features=1)\n",
    "        self.relu = nn.ReLU()\n",
    "        self.sigmoid = nn.Sigmoid()\n",
    "\n",
    "    def forward(self, text, numerical):\n",
    "        text = self.text_embedding(text)\n",
    "        text_output, _ = self.text_rnn(text)\n",
    "        text_output = text_output[:, -1, :]\n",
    "        x = torch.cat([text_output, numerical], dim=1)\n",
    "        x = self.relu(self.linear1(x))\n",
    "        x = self.sigmoid(self.linear2(x))\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a429dbc4-2528-4462-893d-d7d174f31410",
   "metadata": {},
   "outputs": [],
   "source": [
    "text_embedding = nn.Embedding(num_embeddings=10, embedding_dim=5)\n",
    "text_rnn = nn.LSTM(input_size=5, hidden_size=4, batch_first=True)\n",
    "linear1 = nn.Linear(in_features=7, out_features=5)\n",
    "linear2 = nn.Linear(in_features=5, out_features=1)\n",
    "relu = nn.ReLU()\n",
    "sigmoid = nn.Sigmoid()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aba617b0-3c86-4838-8a32-1fb4fe4eb279",
   "metadata": {},
   "outputs": [],
   "source": [
    "text=torch.tensor([1,2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62fe291d-51e0-4103-9446-cb8488afa73f",
   "metadata": {},
   "outputs": [],
   "source": [
    "text=text_embedding(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4f9aaa0-0fd9-49cb-9a70-fd86ead448ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "985060dc-d1dc-4998-b699-c0071df15c37",
   "metadata": {},
   "outputs": [],
   "source": [
    "text_output, _ = text_rnn(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c441ae38-e776-48fa-8e35-1aa527df4f00",
   "metadata": {},
   "outputs": [],
   "source": [
    "text_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "edae58f2-9707-41d1-8752-a7b6bdcc4a03",
   "metadata": {},
   "outputs": [],
   "source": [
    "numer=torch.tensor([[1,2,3],[2,3,4]])\n",
    "x=torch.cat([text_output, numer], dim=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0db6d4f2-4196-47a4-89a0-2f50dae500c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b714222-f481-4628-9ca7-2117d5561ef7",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = relu(linear1(x))\n",
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "155e7868-cf17-494d-ac6a-618b117de603",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = sigmoid(linear2(x))\n",
    "x"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
